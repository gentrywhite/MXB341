---
title: "MXB341 Worksheet 12 - MCMC Diganostics"
output:
  learnr::tutorial:
    theme: yeti
    includes:
    css: ["css/QUT.css","css/QUTtutorial.css"]
  progressive: true
  allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
# if problems with knitting directory:
# set Knit Directory = Document Directory

# install libraries needed for worksheet
knitr::opts_chunk$set(
  fig.align = 'center',
  collapse = TRUE,
  comment = "#>"
)

library(learnr)
library(kableExtra)
library(pander)
library(shiny)
library(MXB341)


```

```{r, echo = FALSE}

htmltools::includeHTML("header.html")
htmltools::includeCSS("./css/QUTtutorial.css")
htmltools::includeCSS("./css/QUT.css")

```


:::{.quote}

"In theory, there is no difference between practice and theory. In practice there is." 

--- Jan van de Snepscheut 

:::


##   MCMC Diagnostics

The Monte Carlo Markov Chain techniques that we have learned so far are based on the idea of drawing random samples from a posterior distribution in order to implement Monte Carlo integration in order to make inferences about our parameters.  Because these techniques are based on random variables and the schemes we have discussed are based on drawing a _sequence_ of samples, there are several opportunities for errors or inefficiencies to come up.  

Notably we need to know:

1.    Are the samples drawn from the stationary target density?
2.    Are the samples a good approximation of a representative sample of independent draws from the the target density
3.    Finally, how does my selected model compare to other possible models?

We can use tools like cummulative means plots and the Brooks-Gelman-Rubin Potential Scale Reduction Factor to determine convergence, and tools like autocorrelation plots and effective sample size to measure the quality of our samples.  Finally we will introduce the deviance information criteria (DIC) as a means of making comparisons between models. 

##    Convergence and Stationarity

:::{.boxed}
**Cummulative Means**

For a target variable $\theta$ and an MCMC scheme generating a sequence
of samples $\theta^{(t)},\theta^{(t+1)},\ldots$ from the target
posterior $\pi(\theta|\mathbf{y})$ the most basic definition of stationarity
is
$$
E\left(\theta^{(t)}|\mathbf{y}\right)=E\left(\theta^{(t+1)}|\mathbf{y}\right).
$$
From this definition it is reasonable to assume that monitoring the
cumulative average of the samples generated by the MCMC scheme can be
used as a tool for monitoring convergence, by plotting $t$ versus the
cumulative mean, i.e.Â for $t=1,\ldots,T$ plot $t$ versus
$$
\bar{\theta}^{(t)}=\frac{1}{t}\sum_{s=1}^t\theta^{(s)}
$$ 
The resulting
plot should reach an stable value for $\bar{\theta}^{(t)}$, indicating
the point where the MCMC scheme achieves stationarity.

:::

:::{.boxed}
**The Brooks-Gelman-Rubin (BGR) potential scale reduction factor:**\

For $m$ independent chains from diverse starting points, compute the
variance estimate for each chain $j$:
$$
s^2_j=\frac{1}{n-1}\sum_{i=1}^n(\theta_{ij}-\bar{\theta}_j)^2
$$
and
let
$$
W=\frac{1}{m}\sum_{j=1}^ms^2_j
$$
be the average of the variance
across the chains and define the overall mean as
$$
\bar{\bar{\theta}}=\frac{1}{m}\sum_{j=1}^m\bar{\theta}_j
$$
and
$$
B=\frac{n}{m-1}\sum_{j=1}^m(\bar{\theta}_j-\bar{\bar{\theta}})^2
$$
and
$$
\widehat{\operatorname{Var}(\theta)}=\left(1-\frac{1}{n}\right)W+\frac{1}{n}B
$$
Then the B-G-R potential scale reduction factor is
$$
\hat{R}=\sqrt{\frac{\widehat{\operatorname{Var}(\theta)}}{W}}.
$$
Ploting the chains together is a useful tool for graphcially assessing whether or not the chains have converged, but calculating $\hat{R}$ is a bit more precise means of assessing convergence. 
Ideally, $\hat{R}$ should be close to $1$, and as a rule of thumb, a value of $\hat{R}<1.1$ is considered sufficiently close to $1$.  

:::

## Question 1
:::{.boxed}

```{r theory-question-1, child='../question-bank/id0054-bayes-BGR.Rmd', eval = TRUE}

```
:::

<button class="solution">
Solution
</button>
:::{.panel}
```{r theory-solution-1, child='../solution-bank/id0054-bayes-BGR.Rmd', eval = TRUE}

```
:::

##    Assessing Samples 

:::{.boxed}
**Autocorrelation:**

The autocorrelation between two samples in an MCMC chain is the Pearson
correlation coefficient between the two samples. It is a function of the
lag or number of samples between them.
$$
\operatorname{Cor}\left(\theta^{(t)},\theta^{(t+k)}\right)=\rho^k.
$$
The
autocorrelation can be easily calculated and plotted to gain some
understanding of the degree of correlation present in the sequence.

This can be done automatically in `R` using the function `acf()`.

```{r eval=FALSE}
acf(theta)
```

:::

:::{.boxed}
**Effective Sample Size (ESS):**

Given the autocorrelation function $\rho^k$ can be used to
compute the *effective* sample size that is less than the actual sample
size $n$.
$$
ESS=\frac{n}{1+2\sum_{k=1}^\infty\rho_k}.
$$
The effective
sample size is a more quantitative measure of the efficiency of MCMC
schemes and can be a useful measure of the reliability of estimates
based on the samples.

This can be computed automatically in `R` using the function `ess()` in the `mcmcse` package.

```{r eval = FALSE}
library(mcmcse)

ess(theta)

```

:::

## Question 2
:::{.boxed}

```{r theory-question-2, child='../question-bank/id0055-bayes-ACF_ESS.Rmd', eval = TRUE}

```
:::

<button class="solution">
Solution
</button>
:::{.panel}
```{r theory-solution-2, child='../solution-bank/id0055-bayes-ACF_ESS.Rmd', eval = TRUE}

```
:::

##    The Deviance Information Criteria

:::{.boxed}
**Deviance Information Criteria**

The deviance information criterion (DIC) is an information criterion
much like the AIC or BIC. It is a measure that takes into account both
the model complexity and goodness of fit in order for use as a model
selection criteria. Defining the deviance as
$$
D(\theta) = -2\log(f(\mathbf{y}|\theta))
$$
or $-2$ times the
log-likelihood, it is a measure of goodness of fit. Model complexity can
also be measured in terms of deviance by one of two measures:
$$
p_D= \overline{D(\theta)}-D(\bar{\theta})
$$
where
$\overline{D(\theta)}$ is the expected value of the deviance, and
$D(\bar{\theta})$ is the deviance evaluated at the expected value of
$\theta$. Alternatively, the measure
$$
p_V = \frac{1}{2}\operatorname{Var}(D(\theta))
$$
can be used a a complexity measure, and the resulting DIC is
$$
DIC = p_D+\overline{D(\theta)},\mbox{ or }D(\bar{\theta})+2p_D
$$
with the second form highlighting the relationship with AIC. Note that $p_V$
can be substituted for $p_D$ if desired, but this is not standard in
most implementations.

One can implement the DIC in any Monte Carlo scheme desired,
$\overline{D(\theta)}$ and $p_V$ can be easily calculated by computing
the log-likelihood at each iteration and computing the mean and
variance. Calculating the $p_D$ consists of calculating the
log-likelihood using the posterior mean of $\theta$.

:::
## Question 3

:::{.boxed}

```{r theory-question-3, child='../question-bank/id0056-bayes-DIC_prac.Rmd', eval = TRUE}

```
:::

<button class="solution">
Solution
</button>
:::{.panel}
```{r theory-solution-3, child='../solution-bank/id0056-bayes-DIC_prac.Rmd', eval = TRUE}

```
:::

## Practical question

### Question 4

:::{.boxed}
```{r prac-question-1, child='../question-bank/id0053-bayes-DIC.Rmd', eval = TRUE}

```
:::

<button class="solution">
Solution
</button>
:::{.panel}
```{r prac-solution-1, child='../solution-bank/id0053-bayes-DIC.Rmd', eval = TRUE}

```
:::

```{r,echo=FALSE}
htmltools::includeHTML("footer.html")
```

